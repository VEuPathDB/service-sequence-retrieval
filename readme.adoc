= Service for sequence retrieval

== Running locally

To build the service in place (produce a jar), run:
```
make jar
```

To build a runnable "test" docker image, run:
```
make docker
```

To execute unit tests, run:
```
make test
```

The service can be brought up via docker, using the sample docker-compose and env files, like this:
```
make docker-compose-clean
make docker-compose-build
make docker-compose-run
```

You might need a traefik to run:
```
cp ~/dev/docker-traefik/docker-compose.yml docker-compose/traefik.yml
docker compose -f  docker-compose/traefik.yml -f docker-compose/docker-compose.yml -f docker-compose/docker-compose.dev.yml up
```

== Configuration

Configuration is handled via docker-compose.yml, which reads values from environment (provided by default by .env or you may specify another file)

Please see `docker-compose/docker-compose.test.yml` and `.env.test` for test configuration.  The file `docker-compose/docker-compose.prod.yml` will be used for production configuration.

== Example queries

See `cURL` scripts in the `src/test/query` folder.  Note: some of these may no longer work.

= Possible upgrades to this README
Here are some things to describe (you can probably think of others... in general orient a person who doesn't know what is going on)
the purpose of the service

* mention that it is async (but that u also have sync endpoints, right?)
* a link to the api docs (here is an example)
* what .bed files and other input look like
* that you are using samtools, and how they help
* how samtools natively reads fasta index into memory, and that got too big
* why u r using SQLite.  mention that it is serverless, and designed to be embedded.  also mention that an upstream process (workflow) will produce SQLite ready file
* how u trick samtools to use SQLite, and, if there is a fork, link to that
